{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WDL 2021 - Final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries and customize seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import pickle\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "from math import floor, sin, cos, sqrt, atan2, radians, asin\n",
    "#from keras.layers import Dense, Dropout, Flatten\n",
    "#from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
    "#from keras.models import Sequential\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, MinMaxScaler\n",
    "#import folium\n",
    "from itertools import combinations\n",
    "#import networkx as nx\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "fig_dim = (16,9)\n",
    "\n",
    "base = '/home/ana/Downloads/noise_data/noise_data/csv_format'\n",
    "#base = '/home/bsilva/Desktop'\n",
    "#base = r'C:\\Users\\Carolina Alves\\OneDrive - Universidade de Aveiro\\WDL competition\\Stage 3/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxiliar functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bar plot function\n",
    "def bar_plot(_x, _y, _data):\n",
    "    fig, axs = plt.subplots(figsize=fig_dim)\n",
    "    axs = sns.barplot(x=_x, y=_y, data=_data)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.draw()\n",
    "    \n",
    "# performs the encoding of categorical features to ordinal numbers\n",
    "def encode_categorical_features(_df, features):\n",
    "    df = _df.copy()\n",
    "    enc = OrdinalEncoder()\n",
    "    df[features] = enc.fit_transform(df[features]).astype(int)\n",
    "    \n",
    "    return enc, df\n",
    "\n",
    "def correlation_matrix (df):\n",
    "    cor = df.corr()\n",
    "    fig,ax = plt.subplots(figsize=(6,5))\n",
    "    sns.heatmap(cor, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening and saving the original dataset\n",
    "# We converted the file from csv to binary in order to read it faster\n",
    "# You do not need to run this cell\n",
    "\n",
    "df = pd.read_csv(base+'/'+\"san_salvario_2019.csv\", sep=\";\")\n",
    "pickle.dump(df, open(base+'/'+\"df_raw_2019\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening data\n",
    "df = pickle.load(open(base+'/'+\"df_raw_2019\", \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Ora</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01-01-2019</td>\n",
       "      <td>00:00</td>\n",
       "      <td>69,7</td>\n",
       "      <td>69,4</td>\n",
       "      <td>73,9</td>\n",
       "      <td>70,5</td>\n",
       "      <td>65,5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01-01-2019</td>\n",
       "      <td>01:00</td>\n",
       "      <td>61</td>\n",
       "      <td>62,6</td>\n",
       "      <td>67</td>\n",
       "      <td>60,7</td>\n",
       "      <td>63,6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01-01-2019</td>\n",
       "      <td>02:00</td>\n",
       "      <td>62</td>\n",
       "      <td>65,8</td>\n",
       "      <td>68,7</td>\n",
       "      <td>59,9</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01-01-2019</td>\n",
       "      <td>03:00</td>\n",
       "      <td>56,3</td>\n",
       "      <td>68</td>\n",
       "      <td>58,1</td>\n",
       "      <td>57,7</td>\n",
       "      <td>60,2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01-01-2019</td>\n",
       "      <td>04:00</td>\n",
       "      <td>55,5</td>\n",
       "      <td>69</td>\n",
       "      <td>56,6</td>\n",
       "      <td>58</td>\n",
       "      <td>59,7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Data    Ora    C1    C2    C3    C4    C5\n",
       "0  01-01-2019  00:00  69,7  69,4  73,9  70,5  65,5\n",
       "1  01-01-2019  01:00    61  62,6    67  60,7  63,6\n",
       "2  01-01-2019  02:00    62  65,8  68,7  59,9    61\n",
       "3  01-01-2019  03:00  56,3    68  58,1  57,7  60,2\n",
       "4  01-01-2019  04:00  55,5    69  56,6    58  59,7"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8760, 7)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data types, uniques and NaN information "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checking type of data, number of unique values and the presence of missing values and zeros**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------------------------------+\n",
      "|         Column          |   Type   | Uniques  |   NaN?   | Number of NaN |   %NaN   | Number of 0s  |   %0s    |\n",
      "+----------------------------------------------------------------------------------------------------------------+\n",
      "|          Data           |  object  |   365    |  False   |       0       |   0.0    |       0       |   0.0    |\n",
      "|           Ora           |  object  |    24    |  False   |       0       |   0.0    |       0       |   0.0    |\n",
      "|           C1            |  object  |   375    |   True   |      864      | 9.86301  |       0       |   0.0    |\n",
      "|           C2            |  object  |   304    |   True   |      341      | 3.89269  |       0       |   0.0    |\n",
      "|           C3            |  object  |   409    |   True   |      56       | 0.63927  |       0       |   0.0    |\n",
      "|           C4            |  object  |   285    |   True   |     1698      | 19.38356 |       0       |   0.0    |\n",
      "|           C5            |  object  |   297    |   True   |     1522      | 17.37443 |       0       |   0.0    |\n",
      "+----------------------------------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "def eda_to_df(df):\n",
    "    header=\"+\" + (\"-\"*112) + \"+\"\n",
    "    form = \"|{:^25s}|{:^10s}|{:^10s}|{:^10s}|{:^15s}|{:^10s}|{:^15s}|{:^10s}|\"\n",
    "    print(header)\n",
    "    print(form.format(\"Column\", \"Type\", \"Uniques\", \"NaN?\", \"Number of NaN\" ,\"%NaN\", \"Number of 0s\" ,\"%0s\"))\n",
    "    print(header)\n",
    "    for col in df.columns:\n",
    "        print(form.format(str(col), # Column\n",
    "                          str(df[col].dtypes), # Type\n",
    "                          str(len(df[col].unique())), # Uniques\n",
    "                          str(df[col].isnull().values.any()), # NaN?\n",
    "                          str(df[col].isnull().sum()), # Number of NaNs\n",
    "                          str(round(((df[col].isnull().sum())/len(df[col]))*100,5)), # %NaN\n",
    "                          str((df[col] == 0).sum()), # Number of 0's\n",
    "                          str(round((((df[col] == 0).sum())/len(df[col]))*100,5))) # %0's\n",
    "              )\n",
    "    print(header)    \n",
    "    \n",
    "    \n",
    "\n",
    "eda_to_df(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANÁLISE - ADICIONAR TEXTO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Removing columns if needed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.drop(['Importe', 'DescripcionImporte'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Removing NaN if needed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Id_Aparcamiento_Destino'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving cleaned dataframe\n",
    "pickle.dump(df_clean_, open(path+'/'+\"df_clean\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEIXEI PARA O CASO DE SER PRECISO UM PROCESSAMENTO SEMELHANTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_loans_clean(base):\n",
    "\n",
    "    df = pd.read_pickle(base + '/'+'df_clean')[[\"Id_Historico_Prestamo\", \"Id_Usuario\", \"Id_Tag_Bicicleta\", \\\n",
    "            \"Fecha_Prestamo\", \"Fecha_Devolucion\", \"Id_Aparcamiento_Origen\", \"Posicion_Origen\", \\\n",
    "            \"Id_Aparcamiento_Destino\", \"Posicion_Destino\"]]\n",
    "    \n",
    "    # Rename columns\n",
    "    # The same bike can have multiple tags over the year.\n",
    "    df = df.rename(columns={\n",
    "        \"Id_Historico_Prestamo\": \"Loan ID\",\n",
    "        \"Id_Usuario\": \"User ID\",\n",
    "        \"Id_Tag_Bicicleta\": \"Tag ID\",\n",
    "        \"Fecha_Prestamo\": \"Start loan\",\n",
    "        \"Fecha_Devolucion\": \"End loan\",\n",
    "        \"Id_Aparcamiento_Origen\": \"ID start station\",\n",
    "        \"Posicion_Origen\": \"Position start\",\n",
    "        \"Id_Aparcamiento_Destino\": \"ID end station\",\n",
    "        \"Posicion_Destino\": \"Position end\"\n",
    "    })\n",
    "    \n",
    "    df['ID end station'] = df['ID end station'].astype(int)\n",
    "    df['ID start station'] = df['ID start station'].astype(int)\n",
    "    \n",
    "    df[\"Start loan\"] = pd.to_datetime(df[\"Start loan\"], format='%Y-%m-%d %H:%M:%S.%f')\n",
    "    df[\"End loan\"] = pd.to_datetime(df[\"End loan\"], format='%Y-%m-%d %H:%M:%S.%f')\n",
    "    \n",
    "    # Auxiliar fields\n",
    "    df['year_prestamo'] = df[\"Start loan\"].dt.year\n",
    "    df['month_prestamo'] = df[\"Start loan\"].dt.month\n",
    "    df['day_prestamo'] = df[\"Start loan\"].dt.day\n",
    "    df['hour_prestamo'] = df[\"Start loan\"].dt.hour\n",
    "    \n",
    "    df['year_devolucion'] = df[\"End loan\"].dt.year\n",
    "    df['month_devolucion'] = df[\"End loan\"].dt.month\n",
    "    df['day_devolucion'] = df[\"End loan\"].dt.day\n",
    "    df['hour_devolucion'] = df[\"End loan\"].dt.hour\n",
    "    \n",
    "    df['duration_hour'] = (df[\"End loan\"]-df[\"Start loan\"]).dt.total_seconds().div(60*60)\n",
    "    df['Fecha_Prestamo_htruncate'] = df['Start loan'].dt.floor('h')\n",
    "        \n",
    "    return df\n",
    "\n",
    "df = get_loans_clean(base)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Another chapter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medidas de combate ao barulho"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- meter a polícia a fazer patrulhas/organização\n",
    "- meter capacidades máximas de pessoas em locais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scalability and Impact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "369.6px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
