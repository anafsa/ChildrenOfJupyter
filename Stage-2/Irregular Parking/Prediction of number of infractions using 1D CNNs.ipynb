{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JeP6xkRIBJco"
   },
   "source": [
    "# Prediction of number of infractions using 1D CNNs\n",
    "## Notebook Template\n",
    "\n",
    "This notebook is one of the mandatory deliverables when you submit your solution (alongside the video pitch). Its structure follows the WDL evaluation criteria and it has dedicated cells where you can add descriptions. Make sure your code is readable as it will be the only technical support the jury will have to evaluate your work.\n",
    "\n",
    "The notebook must:\n",
    "\n",
    "*   üíª have all the code that you want the jury to evaluate\n",
    "*   üß± follow the predefined structure\n",
    "*   üìÑ have markdown descriptions where you find necessary\n",
    "*   üëÄ be saved with all the output that you want the jury to see\n",
    "*   üèÉ‚Äç‚ôÇÔ∏è be runnable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "afB4W0KnutpV"
   },
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ana/anaconda3/envs/data_analysis/lib/python3.7/site-packages/numpy/lib/arraysetops.py:580: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Block</th>\n",
       "      <th>Street</th>\n",
       "      <th>EntryDate</th>\n",
       "      <th>Bylaw</th>\n",
       "      <th>Section</th>\n",
       "      <th>Status</th>\n",
       "      <th>InfractionText</th>\n",
       "      <th>Year</th>\n",
       "      <th>HBLOCK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1400</td>\n",
       "      <td>Kingsway</td>\n",
       "      <td>2017-08-23</td>\n",
       "      <td>2849</td>\n",
       "      <td>17.1</td>\n",
       "      <td>IS</td>\n",
       "      <td>STOP AT A PLACE WHERE A TRAFFIC SIGN PROHIBITS...</td>\n",
       "      <td>2017</td>\n",
       "      <td>1400 KINGSWAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2100</td>\n",
       "      <td>13th Ave E.</td>\n",
       "      <td>2017-08-26</td>\n",
       "      <td>2849</td>\n",
       "      <td>19.1(H)</td>\n",
       "      <td>IS</td>\n",
       "      <td>STOP ON EITHER SIDE OF A LANE WHICH ABUTS COMM...</td>\n",
       "      <td>2017</td>\n",
       "      <td>2100 13TH AVE E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2800</td>\n",
       "      <td>Trinity St.</td>\n",
       "      <td>2017-08-26</td>\n",
       "      <td>2849</td>\n",
       "      <td>17.6(B)</td>\n",
       "      <td>VA</td>\n",
       "      <td>PARK ON A STREET WHERE A TRAFFIC SIGN RESTRICT...</td>\n",
       "      <td>2017</td>\n",
       "      <td>2800 TRINITY ST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200</td>\n",
       "      <td>17th Ave W.</td>\n",
       "      <td>2017-08-27</td>\n",
       "      <td>2849</td>\n",
       "      <td>17.5(B)</td>\n",
       "      <td>IS</td>\n",
       "      <td>STOP WITHIN 6 METRES OF THE NEAREST EDGE OF TH...</td>\n",
       "      <td>2017</td>\n",
       "      <td>200 17TH AVE W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1900</td>\n",
       "      <td>4th Ave W.</td>\n",
       "      <td>2017-08-19</td>\n",
       "      <td>2952</td>\n",
       "      <td>5(4)(a)(ii)</td>\n",
       "      <td>IS</td>\n",
       "      <td>PARK IN A METERED SPACE IF THE PARKING METER H...</td>\n",
       "      <td>2017</td>\n",
       "      <td>1900 4TH AVE W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1318730</th>\n",
       "      <td>1000</td>\n",
       "      <td>Smithe St.</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>2952</td>\n",
       "      <td>5(4)(a)(ii)</td>\n",
       "      <td>IS</td>\n",
       "      <td>PARK IN A METERED SPACE IF THE PARKING METER H...</td>\n",
       "      <td>2017</td>\n",
       "      <td>1000 SMITHE ST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1318731</th>\n",
       "      <td>2500</td>\n",
       "      <td>Yew St.</td>\n",
       "      <td>2017-04-24</td>\n",
       "      <td>2952</td>\n",
       "      <td>5(4)(a)(ii)</td>\n",
       "      <td>IS</td>\n",
       "      <td>PARK IN A METERED SPACE IF THE PARKING METER H...</td>\n",
       "      <td>2017</td>\n",
       "      <td>2500 YEW ST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1318732</th>\n",
       "      <td>600</td>\n",
       "      <td>Seymour St.</td>\n",
       "      <td>2017-04-20</td>\n",
       "      <td>2952</td>\n",
       "      <td>5(4)(a)(ii)</td>\n",
       "      <td>IS</td>\n",
       "      <td>PARK IN A METERED SPACE IF THE PARKING METER H...</td>\n",
       "      <td>2017</td>\n",
       "      <td>600 SEYMOUR ST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1318733</th>\n",
       "      <td>1300</td>\n",
       "      <td>Robson St.</td>\n",
       "      <td>2017-04-22</td>\n",
       "      <td>2952</td>\n",
       "      <td>5(4)(a)(ii)</td>\n",
       "      <td>IS</td>\n",
       "      <td>PARK IN A METERED SPACE IF THE PARKING METER H...</td>\n",
       "      <td>2017</td>\n",
       "      <td>1300 ROBSON ST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1318734</th>\n",
       "      <td>1700</td>\n",
       "      <td>Davie St.</td>\n",
       "      <td>2017-04-22</td>\n",
       "      <td>2952</td>\n",
       "      <td>5(4)(a)(ii)</td>\n",
       "      <td>IS</td>\n",
       "      <td>PARK IN A METERED SPACE IF THE PARKING METER H...</td>\n",
       "      <td>2017</td>\n",
       "      <td>1700 DAVIE ST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1318735 rows √ó 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Block       Street  EntryDate  Bylaw      Section Status  \\\n",
       "0         1400     Kingsway 2017-08-23   2849         17.1     IS   \n",
       "1         2100  13th Ave E. 2017-08-26   2849      19.1(H)     IS   \n",
       "2         2800  Trinity St. 2017-08-26   2849      17.6(B)     VA   \n",
       "3          200  17th Ave W. 2017-08-27   2849      17.5(B)     IS   \n",
       "4         1900   4th Ave W. 2017-08-19   2952  5(4)(a)(ii)     IS   \n",
       "...        ...          ...        ...    ...          ...    ...   \n",
       "1318730   1000   Smithe St. 2017-04-23   2952  5(4)(a)(ii)     IS   \n",
       "1318731   2500      Yew St. 2017-04-24   2952  5(4)(a)(ii)     IS   \n",
       "1318732    600  Seymour St. 2017-04-20   2952  5(4)(a)(ii)     IS   \n",
       "1318733   1300   Robson St. 2017-04-22   2952  5(4)(a)(ii)     IS   \n",
       "1318734   1700    Davie St. 2017-04-22   2952  5(4)(a)(ii)     IS   \n",
       "\n",
       "                                            InfractionText  Year  \\\n",
       "0        STOP AT A PLACE WHERE A TRAFFIC SIGN PROHIBITS...  2017   \n",
       "1        STOP ON EITHER SIDE OF A LANE WHICH ABUTS COMM...  2017   \n",
       "2        PARK ON A STREET WHERE A TRAFFIC SIGN RESTRICT...  2017   \n",
       "3        STOP WITHIN 6 METRES OF THE NEAREST EDGE OF TH...  2017   \n",
       "4        PARK IN A METERED SPACE IF THE PARKING METER H...  2017   \n",
       "...                                                    ...   ...   \n",
       "1318730  PARK IN A METERED SPACE IF THE PARKING METER H...  2017   \n",
       "1318731  PARK IN A METERED SPACE IF THE PARKING METER H...  2017   \n",
       "1318732  PARK IN A METERED SPACE IF THE PARKING METER H...  2017   \n",
       "1318733  PARK IN A METERED SPACE IF THE PARKING METER H...  2017   \n",
       "1318734  PARK IN A METERED SPACE IF THE PARKING METER H...  2017   \n",
       "\n",
       "                  HBLOCK  \n",
       "0          1400 KINGSWAY  \n",
       "1        2100 13TH AVE E  \n",
       "2        2800 TRINITY ST  \n",
       "3         200 17TH AVE W  \n",
       "4         1900 4TH AVE W  \n",
       "...                  ...  \n",
       "1318730   1000 SMITHE ST  \n",
       "1318731      2500 YEW ST  \n",
       "1318732   600 SEYMOUR ST  \n",
       "1318733   1300 ROBSON ST  \n",
       "1318734    1700 DAVIE ST  \n",
       "\n",
       "[1318735 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# O ficheiro √© demasiado grande para o github\n",
    "df = pd.read_csv('/home/ana/Downloads/parking-tickets-2017-2019_WDL.csv', sep=';', index_col=0,\n",
    "                 parse_dates=['EntryDate'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------+\n",
      "+     Column     |      Type      | Uniques  | NaN?  |\n",
      "+----------------------------------------------------+\n",
      "+     Block      |     int64      |   129    | False |\n",
      "+     Street     |     object     |   1785   | False |\n",
      "+   EntryDate    | datetime64[ns] |   1089   | False |\n",
      "+     Bylaw      |     int64      |    5     | False |\n",
      "+    Section     |     object     |    98    | False |\n",
      "+     Status     |     object     |    5     | False |\n",
      "+ InfractionText |     object     |   123    | False |\n",
      "+      Year      |     int64      |    3     | False |\n",
      "+     HBLOCK     |     object     |  15219   | False |\n",
      "+----------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "def eda_to_df(df):\n",
    "    header=\"+\" + (\"-\"*52) + \"+\"\n",
    "    form = \"+{:^16s}|{:^16s}|{:^10s}|{:^7s}|\"\n",
    "    print(header)\n",
    "    print(form.format(\"Column\", \"Type\", \"Uniques\", \"NaN?\"))\n",
    "    print(header)\n",
    "    for col in df.columns:\n",
    "        print(form.format(str(col), str(df[col].dtypes), str(len(df[col].unique())), \n",
    "                          str(df[col].isnull().values.any()) ))\n",
    "    print(header)\n",
    "eda_to_df(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_feature_study(_df, feature, horizontal=False, treshould=0, plot=True):\n",
    "    df = _df.copy()\n",
    "    df = df[feature].value_counts().to_frame()\n",
    "    \n",
    "    if treshould>0 :\n",
    "        df = df[ df[feature] >= treshould ]\n",
    "    \n",
    "    df = df.reset_index()\n",
    "    df = df.rename(columns={feature: \"Count\"})\n",
    "    df = df.rename(columns={\"index\": feature})\n",
    "       \n",
    "    if plot:\n",
    "        fig, ax = pyplot.subplots()#figsize=(20,15))\n",
    "    \n",
    "        if horizontal :\n",
    "            sns.barplot(x=\"Count\", y=feature, data=df, ax=ax)\n",
    "        else:\n",
    "            sns.barplot(x=feature, y=\"Count\", data=df, ax=ax)\n",
    "        \n",
    "        ax.plot()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InfractionText</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21</td>\n",
       "      <td>649308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>144750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>106396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>70446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>91</td>\n",
       "      <td>42980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   InfractionText   Count\n",
       "0              21  649308\n",
       "1              37  144750\n",
       "2              28  106396\n",
       "3              30   70446\n",
       "4              91   42980"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = OrdinalEncoder()\n",
    "df[\"InfractionText\"] = enc.fit_transform(df[[\"InfractionText\"]]).astype(int)\n",
    "\n",
    "df_infraction = categorical_feature_study(df, \"InfractionText\", horizontal=True, treshould=10000, plot=False)\n",
    "df_infraction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Street</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1688</td>\n",
       "      <td>43603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1654</td>\n",
       "      <td>31322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>806</td>\n",
       "      <td>29818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1343</td>\n",
       "      <td>28612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1348</td>\n",
       "      <td>28438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Street  Count\n",
       "0    1688  43603\n",
       "1    1654  31322\n",
       "2     806  29818\n",
       "3    1343  28612\n",
       "4    1348  28438"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = OrdinalEncoder()\n",
    "df[\"Street\"] = enc.fit_transform(df[[\"Street\"]]).astype(int)\n",
    "\n",
    "df_streets = categorical_feature_study(df, \"Street\", horizontal=True, treshould=10000, plot=False)\n",
    "df_streets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of infractions per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EntryDate</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>1487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>1341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>1358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>1413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084</th>\n",
       "      <td>2019-12-27</td>\n",
       "      <td>1155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1085</th>\n",
       "      <td>2019-12-28</td>\n",
       "      <td>1015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>2019-12-29</td>\n",
       "      <td>903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1087</th>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>1083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1088</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>1222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1089 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      EntryDate  Count\n",
       "0    2017-01-02    870\n",
       "1    2017-01-03   1487\n",
       "2    2017-01-04   1341\n",
       "3    2017-01-05   1358\n",
       "4    2017-01-06   1413\n",
       "...         ...    ...\n",
       "1084 2019-12-27   1155\n",
       "1085 2019-12-28   1015\n",
       "1086 2019-12-29    903\n",
       "1087 2019-12-30   1083\n",
       "1088 2019-12-31   1222\n",
       "\n",
       "[1089 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nInfractionsPerDay = df.groupby(['EntryDate']) \\\n",
    "                        .count() \\\n",
    "                        .rename(columns={'Block':'Count'})[['Count']] \\\n",
    "                        .reset_index()\n",
    "nInfractionsPerDay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EntryDate</th>\n",
       "      <th>InfractionText</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>21</td>\n",
       "      <td>638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>27</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>28</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>37</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15764</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>40</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15765</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>59</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15766</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>60</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15767</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>63</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15768</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>84</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15769 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       EntryDate  InfractionText  Count\n",
       "0     2017-01-02              19      3\n",
       "1     2017-01-02              21    638\n",
       "2     2017-01-02              27     15\n",
       "3     2017-01-02              28     45\n",
       "4     2017-01-02              37     44\n",
       "...          ...             ...    ...\n",
       "15764 2019-12-31              40     12\n",
       "15765 2019-12-31              59     18\n",
       "15766 2019-12-31              60    154\n",
       "15767 2019-12-31              63      8\n",
       "15768 2019-12-31              84      9\n",
       "\n",
       "[15769 rows x 3 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "popular_infractions = df_infraction.InfractionText.tolist()\n",
    "\n",
    "# number of Infractions per Day and per Type\n",
    "nIDT = df.copy()\n",
    "nIDT = nIDT[nIDT[\"InfractionText\"].isin(popular_infractions)]\n",
    "nIDT = nIDT.groupby(['EntryDate', 'InfractionText']) \\\n",
    "                                .count() \\\n",
    "                                .rename(columns={'Block':'Count'})[['Count']]\\\n",
    "                                .reset_index()\n",
    "nIDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EntryDate</th>\n",
       "      <th>InfractionText</th>\n",
       "      <th>Street</th>\n",
       "      <th>Count</th>\n",
       "      <th>Street_str</th>\n",
       "      <th>InfractionText_str</th>\n",
       "      <th>Street_&amp;_Infraction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>21</td>\n",
       "      <td>87</td>\n",
       "      <td>44</td>\n",
       "      <td>87</td>\n",
       "      <td>21</td>\n",
       "      <td>87___21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>21</td>\n",
       "      <td>326</td>\n",
       "      <td>31</td>\n",
       "      <td>326</td>\n",
       "      <td>21</td>\n",
       "      <td>326___21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>21</td>\n",
       "      <td>847</td>\n",
       "      <td>21</td>\n",
       "      <td>847</td>\n",
       "      <td>21</td>\n",
       "      <td>847___21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>21</td>\n",
       "      <td>1379</td>\n",
       "      <td>29</td>\n",
       "      <td>1379</td>\n",
       "      <td>21</td>\n",
       "      <td>1379___21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>28</td>\n",
       "      <td>1379</td>\n",
       "      <td>4</td>\n",
       "      <td>1379</td>\n",
       "      <td>28</td>\n",
       "      <td>1379___28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44579</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>60</td>\n",
       "      <td>1688</td>\n",
       "      <td>34</td>\n",
       "      <td>1688</td>\n",
       "      <td>60</td>\n",
       "      <td>1688___60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44580</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>63</td>\n",
       "      <td>1014</td>\n",
       "      <td>1</td>\n",
       "      <td>1014</td>\n",
       "      <td>63</td>\n",
       "      <td>1014___63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44581</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>63</td>\n",
       "      <td>1343</td>\n",
       "      <td>1</td>\n",
       "      <td>1343</td>\n",
       "      <td>63</td>\n",
       "      <td>1343___63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44582</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>63</td>\n",
       "      <td>1689</td>\n",
       "      <td>1</td>\n",
       "      <td>1689</td>\n",
       "      <td>63</td>\n",
       "      <td>1689___63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44583</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>84</td>\n",
       "      <td>339</td>\n",
       "      <td>2</td>\n",
       "      <td>339</td>\n",
       "      <td>84</td>\n",
       "      <td>339___84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44584 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       EntryDate  InfractionText  Street  Count Street_str InfractionText_str  \\\n",
       "0     2017-01-02              21      87     44         87                 21   \n",
       "1     2017-01-02              21     326     31        326                 21   \n",
       "2     2017-01-02              21     847     21        847                 21   \n",
       "3     2017-01-02              21    1379     29       1379                 21   \n",
       "4     2017-01-02              28    1379      4       1379                 28   \n",
       "...          ...             ...     ...    ...        ...                ...   \n",
       "44579 2019-12-31              60    1688     34       1688                 60   \n",
       "44580 2019-12-31              63    1014      1       1014                 63   \n",
       "44581 2019-12-31              63    1343      1       1343                 63   \n",
       "44582 2019-12-31              63    1689      1       1689                 63   \n",
       "44583 2019-12-31              84     339      2        339                 84   \n",
       "\n",
       "      Street_&_Infraction  \n",
       "0                 87___21  \n",
       "1                326___21  \n",
       "2                847___21  \n",
       "3               1379___21  \n",
       "4               1379___28  \n",
       "...                   ...  \n",
       "44579           1688___60  \n",
       "44580           1014___63  \n",
       "44581           1343___63  \n",
       "44582           1689___63  \n",
       "44583            339___84  \n",
       "\n",
       "[44584 rows x 7 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "popular_streets = df_streets.Street.tolist()\n",
    "\n",
    "# number of Infractions per Day per Type per Street\n",
    "nIDTS = df.copy()\n",
    "nIDTS = nIDTS[(nIDTS[\"Street\"].isin(popular_streets)) & (nIDTS[\"InfractionText\"].isin(popular_infractions))]\n",
    "nIDTS = nIDTS.groupby(['EntryDate', 'InfractionText', 'Street']) \\\n",
    "                                .count() \\\n",
    "                                .rename(columns={'Block':'Count'})[['Count']]\\\n",
    "                                .reset_index()\n",
    "\n",
    "nIDTS['Street_str'] = nIDTS['Street'].astype(str)\n",
    "nIDTS['InfractionText_str'] = nIDTS['InfractionText'].astype(str)\n",
    "nIDTS['Street_&_Infraction'] = nIDTS['Street_str'] + [\"___\"]*len(nIDTS) + nIDTS['InfractionText_str']\n",
    "nIDTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'HARDataset/train/Inertial Signals/total_acc_x_train.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-80e260eca8f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;31m# run the experiment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m \u001b[0mrun_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-80e260eca8f3>\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(repeats)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrun_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepeats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;31m# load data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;31m# repeat experiment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-80e260eca8f3>\u001b[0m in \u001b[0;36mload_dataset\u001b[0;34m(prefix)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;31m# load all train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'HARDataset/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;31m# load all test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-80e260eca8f3>\u001b[0m in \u001b[0;36mload_dataset_group\u001b[0;34m(group, prefix)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mfilenames\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'body_gyro_x_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'body_gyro_y_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'body_gyro_z_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.txt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m# load input data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0;31m# load class output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/y_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-80e260eca8f3>\u001b[0m in \u001b[0;36mload_group\u001b[0;34m(filenames, prefix)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mloaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m                 \u001b[0mloaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# stack group so that features are the 3rd dimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-80e260eca8f3>\u001b[0m in \u001b[0;36mload_file\u001b[0;34m(filepath)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# load a single file as a numpy array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mdataframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelim_whitespace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/WDL/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/WDL/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/WDL/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/WDL/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1048\u001b[0m             )\n\u001b[1;32m   1049\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/WDL/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/WDL/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \"\"\"\n\u001b[0;32m-> 1362\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/WDL/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'HARDataset/train/Inertial Signals/total_acc_x_train.txt'"
     ]
    }
   ],
   "source": [
    "# cnn model\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import dstack\n",
    "from pandas import read_csv\n",
    "from matplotlib import pyplot\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# load a single file as a numpy array\n",
    "def load_file(filepath):\n",
    "    dataframe = read_csv(filepath, header=None, delim_whitespace=True)\n",
    "    return dataframe.values\n",
    "\n",
    "# load a list of files and return as a 3d numpy array\n",
    "def load_group(filenames, prefix=''):\n",
    "    loaded = list()\n",
    "    for name in filenames:\n",
    "        data = load_file(prefix + name)\n",
    "        loaded.append(data)\n",
    "    # stack group so that features are the 3rd dimension\n",
    "    loaded = dstack(loaded)\n",
    "    return loaded\n",
    "\n",
    "# load a dataset group, such as train or test\n",
    "def load_dataset_group(group, prefix=''):\n",
    "    filepath = prefix + group + '/Inertial Signals/'\n",
    "    # load all 9 files as a single array\n",
    "    filenames = list()\n",
    "    # total acceleration\n",
    "    filenames += ['total_acc_x_'+group+'.txt', 'total_acc_y_'+group+'.txt', 'total_acc_z_'+group+'.txt']\n",
    "    # body acceleration\n",
    "    filenames += ['body_acc_x_'+group+'.txt', 'body_acc_y_'+group+'.txt', 'body_acc_z_'+group+'.txt']\n",
    "    # body gyroscope\n",
    "    filenames += ['body_gyro_x_'+group+'.txt', 'body_gyro_y_'+group+'.txt', 'body_gyro_z_'+group+'.txt']\n",
    "    # load input data\n",
    "    X = load_group(filenames, filepath)\n",
    "    # load class output\n",
    "    y = load_file(prefix + group + '/y_'+group+'.txt')\n",
    "    return X, y\n",
    "\n",
    "# load the dataset, returns train and test X and y elements\n",
    "def load_dataset(prefix=''):\n",
    "    # load all train\n",
    "    trainX, trainy = load_dataset_group('train', prefix + 'HARDataset/')\n",
    "    print(trainX.shape, trainy.shape)\n",
    "    # load all test\n",
    "    testX, testy = load_dataset_group('test', prefix + 'HARDataset/')\n",
    "    print(testX.shape, testy.shape)\n",
    "    # zero-offset class values\n",
    "    trainy = trainy - 1\n",
    "    testy = testy - 1\n",
    "    # one hot encode y\n",
    "    trainy = to_categorical(trainy)\n",
    "    testy = to_categorical(testy)\n",
    "    print(trainX.shape, trainy.shape, testX.shape, testy.shape)\n",
    "    return trainX, trainy, testX, testy\n",
    "\n",
    "# fit and evaluate a model\n",
    "def evaluate_model(trainX, trainy, testX, testy):\n",
    "    verbose, epochs, batch_size = 0, 10, 32\n",
    "    n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(n_timesteps,n_features)))\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # fit network\n",
    "    model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    # evaluate model\n",
    "    _, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
    "    return accuracy\n",
    "\n",
    "# summarize scores\n",
    "def summarize_results(scores):\n",
    "    print(scores)\n",
    "    m, s = mean(scores), std(scores)\n",
    "    print('Accuracy: %.3f%% (+/-%.3f)' % (m, s))\n",
    "\n",
    "# run an experiment\n",
    "def run_experiment(repeats=10):\n",
    "    # load data\n",
    "    trainX, trainy, testX, testy = load_dataset()\n",
    "    # repeat experiment\n",
    "    scores = list()\n",
    "    for r in range(repeats):\n",
    "        score = evaluate_model(trainX, trainy, testX, testy)\n",
    "        score = score * 100.0\n",
    "        print('>#%d: %.3f' % (r+1, score))\n",
    "        scores.append(score)\n",
    "    # summarize results\n",
    "    summarize_results(scores)\n",
    "\n",
    "# run the experiment\n",
    "run_experiment()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Notebook Submission Template.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
