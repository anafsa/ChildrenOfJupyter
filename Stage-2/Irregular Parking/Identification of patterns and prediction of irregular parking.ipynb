{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JeP6xkRIBJco"
   },
   "source": [
    "# World Data League 2021\n",
    "## Notebook Template\n",
    "\n",
    "This notebook is one of the mandatory deliverables when you submit your solution (alongside the video pitch). Its structure follows the WDL evaluation criteria and it has dedicated cells where you can add descriptions. Make sure your code is readable as it will be the only technical support the jury will have to evaluate your work.\n",
    "\n",
    "The notebook must:\n",
    "\n",
    "*   üíª have all the code that you want the jury to evaluate\n",
    "*   üß± follow the predefined structure\n",
    "*   üìÑ have markdown descriptions where you find necessary\n",
    "*   üëÄ be saved with all the output that you want the jury to see\n",
    "*   üèÉ‚Äç‚ôÇÔ∏è be runnable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "63ltgxp_rOpI"
   },
   "source": [
    "## Introduction\n",
    "Describe how you framed the challenge by telling us what problem are you trying to solve and how your solution solves that problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hp34gOznrwrq"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C8rCpNajszur"
   },
   "source": [
    "## Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries and customize seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "afB4W0KnutpV"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "import requests\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "sns.set_color_codes(\"pastel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data from csv and preprocess it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ana/anaconda3/envs/data_analysis/lib/python3.7/site-packages/numpy/lib/arraysetops.py:580: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Block</th>\n",
       "      <th>Street</th>\n",
       "      <th>EntryDate</th>\n",
       "      <th>Bylaw</th>\n",
       "      <th>Section</th>\n",
       "      <th>Status</th>\n",
       "      <th>InfractionText</th>\n",
       "      <th>Year</th>\n",
       "      <th>HBLOCK</th>\n",
       "      <th>Infraction_Stage</th>\n",
       "      <th>Infraction_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1400</td>\n",
       "      <td>Kingsway</td>\n",
       "      <td>2017-08-23</td>\n",
       "      <td>2849</td>\n",
       "      <td>17.1</td>\n",
       "      <td>IS</td>\n",
       "      <td>STOP AT A PLACE WHERE A TRAFFIC SIGN PROHIBITS...</td>\n",
       "      <td>2017</td>\n",
       "      <td>1400 KINGSWAY</td>\n",
       "      <td>0</td>\n",
       "      <td>STOP OR PARK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2100</td>\n",
       "      <td>13th Ave E.</td>\n",
       "      <td>2017-08-26</td>\n",
       "      <td>2849</td>\n",
       "      <td>19.1(H)</td>\n",
       "      <td>IS</td>\n",
       "      <td>STOP ON EITHER SIDE OF A LANE WHICH ABUTS COMM...</td>\n",
       "      <td>2017</td>\n",
       "      <td>2100 13TH AVE E</td>\n",
       "      <td>0</td>\n",
       "      <td>STOP OR PARK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2800</td>\n",
       "      <td>Trinity St.</td>\n",
       "      <td>2017-08-26</td>\n",
       "      <td>2849</td>\n",
       "      <td>17.6(B)</td>\n",
       "      <td>VA</td>\n",
       "      <td>PARK ON A STREET WHERE A TRAFFIC SIGN RESTRICT...</td>\n",
       "      <td>2017</td>\n",
       "      <td>2800 TRINITY ST</td>\n",
       "      <td>0</td>\n",
       "      <td>STOP OR PARK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200</td>\n",
       "      <td>17th Ave W.</td>\n",
       "      <td>2017-08-27</td>\n",
       "      <td>2849</td>\n",
       "      <td>17.5(B)</td>\n",
       "      <td>IS</td>\n",
       "      <td>STOP WITHIN 6 METRES OF THE NEAREST EDGE OF TH...</td>\n",
       "      <td>2017</td>\n",
       "      <td>200 17TH AVE W</td>\n",
       "      <td>0</td>\n",
       "      <td>STOP OR PARK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1900</td>\n",
       "      <td>4th Ave W.</td>\n",
       "      <td>2017-08-19</td>\n",
       "      <td>2952</td>\n",
       "      <td>5(4)(a)(ii)</td>\n",
       "      <td>IS</td>\n",
       "      <td>PARK IN A METERED SPACE IF THE PARKING METER H...</td>\n",
       "      <td>2017</td>\n",
       "      <td>1900 4TH AVE W</td>\n",
       "      <td>0</td>\n",
       "      <td>METERED</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Block       Street  EntryDate  Bylaw      Section Status  \\\n",
       "0   1400     Kingsway 2017-08-23   2849         17.1     IS   \n",
       "1   2100  13th Ave E. 2017-08-26   2849      19.1(H)     IS   \n",
       "2   2800  Trinity St. 2017-08-26   2849      17.6(B)     VA   \n",
       "3    200  17th Ave W. 2017-08-27   2849      17.5(B)     IS   \n",
       "4   1900   4th Ave W. 2017-08-19   2952  5(4)(a)(ii)     IS   \n",
       "\n",
       "                                      InfractionText  Year           HBLOCK  \\\n",
       "0  STOP AT A PLACE WHERE A TRAFFIC SIGN PROHIBITS...  2017    1400 KINGSWAY   \n",
       "1  STOP ON EITHER SIDE OF A LANE WHICH ABUTS COMM...  2017  2100 13TH AVE E   \n",
       "2  PARK ON A STREET WHERE A TRAFFIC SIGN RESTRICT...  2017  2800 TRINITY ST   \n",
       "3  STOP WITHIN 6 METRES OF THE NEAREST EDGE OF TH...  2017   200 17TH AVE W   \n",
       "4  PARK IN A METERED SPACE IF THE PARKING METER H...  2017   1900 4TH AVE W   \n",
       "\n",
       "   Infraction_Stage Infraction_Type  \n",
       "0                 0    STOP OR PARK  \n",
       "1                 0    STOP OR PARK  \n",
       "2                 0    STOP OR PARK  \n",
       "3                 0    STOP OR PARK  \n",
       "4                 0         METERED  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get stage of infraction\n",
    "def get_stage(text):\n",
    "    if 'STAGE 1' in text:\n",
    "        return 1\n",
    "    elif 'STAGE 2' in text:\n",
    "        return 2\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Get infraction type\n",
    "# We created 8 types of infractions based on the infraction text\n",
    "def get_infraction_type(text):\n",
    "    if 'WASTING WATER' in text:\n",
    "        return 'WASTING WATER'\n",
    "    elif 'OUTSIDE PERMITTED' in text:\n",
    "        return 'WATER LAWN/FIELD... OUTSIDE PERMITTED HOUR/DAY'\n",
    "    elif 'METERED' in text:\n",
    "        return 'METERED'\n",
    "    elif 'LARGE VEHICLE - BE PARKED' in text:\n",
    "        return 'LARGE VEHICLE PARKED INCORRECTLY'\n",
    "    elif 'CAUSE, ALLOW OR PERMIT' in text:\n",
    "        return 'CAUSE, ALLOW OR PERMIT'\n",
    "    elif 'WATER' in text or 'WASH' in text:\n",
    "        return 'WATER - OTHER'\n",
    "    elif ('STOP OR PARK' in text) or ('STOP' in text) or ('PARK' in text):\n",
    "        return 'STOP OR PARK'\n",
    "    else:\n",
    "        return 'OTHER'\n",
    "\n",
    "# Get infraction data and pre-processing\n",
    "def get_parking_tickets_data():\n",
    "    # O ficheiro √© demasiado grande para o github\n",
    "    df = pd.read_csv('/home/ana/Downloads/parking-tickets-2017-2019_WDL.csv', sep=';', index_col=0,\n",
    "                    parse_dates=['EntryDate'])\n",
    "    # Some infractions are the same, but have a final dot in them! Remove that dot in order \n",
    "    # to not consider those infractions as distincts\n",
    "    df['InfractionText'] = df['InfractionText'].str.rstrip('.') \n",
    "    \n",
    "    # There are repeated infractions with different stages (or without a stage)\n",
    "    df['Infraction_Stage'] = df['InfractionText'].apply(lambda x: get_stage(x))\n",
    "    df['InfractionText'] = df['InfractionText'].str.rstrip(' - STAGE 1').str.rstrip(' - STAGE 2') \n",
    "    df['Infraction_Type'] = df['InfractionText'].apply(lambda x: get_infraction_type(x))\n",
    "    return df\n",
    "\n",
    "df = get_parking_tickets_data()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each column, check type of data, number of unique values and the presence of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------+\n",
      "+     Column     |      Type      | Uniques  | NaN?  |\n",
      "+----------------------------------------------------+\n",
      "+     Block      |     int64      |   129    | False |\n",
      "+     Street     |     object     |   1785   | False |\n",
      "+   EntryDate    | datetime64[ns] |   1089   | False |\n",
      "+     Bylaw      |     int64      |    5     | False |\n",
      "+    Section     |     object     |    98    | False |\n",
      "+     Status     |     object     |    5     | False |\n",
      "+ InfractionText |     object     |    92    | False |\n",
      "+      Year      |     int64      |    3     | False |\n",
      "+     HBLOCK     |     object     |  15219   | False |\n",
      "+Infraction_Stage|     int64      |    3     | False |\n",
      "+Infraction_Type |     object     |    8     | False |\n",
      "+----------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "def eda_to_df(df):\n",
    "    header=\"+\" + (\"-\"*52) + \"+\"\n",
    "    form = \"+{:^16s}|{:^16s}|{:^10s}|{:^7s}|\"\n",
    "    print(header)\n",
    "    print(form.format(\"Column\", \"Type\", \"Uniques\", \"NaN?\"))\n",
    "    print(header)\n",
    "    for col in df.columns:\n",
    "        print(form.format(str(col), str(df[col].dtypes), str(len(df[col].unique())), \n",
    "                          str(df[col].isnull().values.any()) ))\n",
    "    print(header)\n",
    "    \n",
    "eda_to_df(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_feature_study(_df, feature, horizontal=False, treshould=0, plot=True):\n",
    "    df = _df.copy()\n",
    "    df = df[feature].value_counts().to_frame()\n",
    "    \n",
    "    if treshould>0 :\n",
    "        df = df[ df[feature] >= treshould ]\n",
    "    \n",
    "    df = df.reset_index()\n",
    "    df = df.rename(columns={feature: \"Count\"})\n",
    "    df = df.rename(columns={\"index\": feature})\n",
    "       \n",
    "    if plot:\n",
    "        fig, ax = pyplot.subplots()#figsize=(20,15))\n",
    "    \n",
    "        if horizontal :\n",
    "            sns.barplot(x=\"Count\", y=feature, data=df, ax=ax)\n",
    "        else:\n",
    "            sns.barplot(x=feature, y=\"Count\", data=df, ax=ax)\n",
    "        \n",
    "        ax.plot()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_feature_study(df, \"InfractionText\", horizontal=True, treshould=10000).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_feature_study(df, \"Infraction_Type\", horizontal=True).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_feature_study(df, \"Street\", horizontal=True, treshould=10000).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_feature_study(df, \"Year\", horizontal=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_feature_study(df, \"Bylaw\", horizontal=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_feature_study(df, \"HBLOCK\", horizontal=True, treshould=5000).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OrdinalEncoder()\n",
    "df[\"InfractionText\"] = enc.fit_transform(df[[\"InfractionText\"]]).astype(int)\n",
    "\n",
    "df_infraction = categorical_feature_study(df, \"InfractionText\", horizontal=True, treshould=10000, plot=False)\n",
    "df_infraction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OrdinalEncoder()\n",
    "df[\"Street\"] = enc.fit_transform(df[[\"Street\"]]).astype(int)\n",
    "\n",
    "df_streets = categorical_feature_study(df, \"Street\", horizontal=True, treshould=10000, plot=False)\n",
    "df_streets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of infractions per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nInfractionsPerDay = df.groupby(['EntryDate']) \\\n",
    "                        .count() \\\n",
    "                        .rename(columns={'Block':'Count'})[['Count']] \\\n",
    "                        .reset_index()\n",
    "\n",
    "# Obtain the top 3 local maximums and the top 3 local minimums \n",
    "minimos = nInfractionsPerDay[nInfractionsPerDay.Count<400]\n",
    "maximos = nInfractionsPerDay[nInfractionsPerDay.Count>1850]\n",
    "\n",
    "fig, ax = pyplot.subplots(figsize=(15,12))\n",
    "sns.lineplot(data=nInfractionsPerDay, x=\"EntryDate\", y=\"Count\", ax=ax, label=\"Number of infractions per day\")\n",
    "sns.regplot(data=minimos, x=\"EntryDate\", y=\"Count\", fit_reg=False, \n",
    "            scatter_kws={\"color\":\"darkred\",\"alpha\":0.3,\"s\":200})\n",
    "sns.regplot(data=maximos, x=\"EntryDate\", y=\"Count\", fit_reg=False, \n",
    "            scatter_kws={\"color\":\"green\",\"alpha\":0.3,\"s\":200})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existem 3 m√≠nimos locais que chamam √† aten√ß√£o (datas...) e 3 m√°ximos. Real√ßar os 2 n√≠nimos cujo valor √© de 5 e 1 e dizer que s√£o extremamente baixos dados os outros valores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of infractions per day per type of infraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_infractions = df_infraction.InfractionText.tolist()\n",
    "\n",
    "# number of Infractions per Day and per Type\n",
    "nIDT = df.copy()\n",
    "nIDT = nIDT[nIDT[\"InfractionText\"].isin(popular_infractions)]\n",
    "nIDT = nIDT.groupby(['EntryDate', 'InfractionText']) \\\n",
    "                                .count() \\\n",
    "                                .rename(columns={'Block':'Count'})[['Count']]\\\n",
    "                                .reset_index()\n",
    "nIDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = pyplot.subplots(figsize=(25,20))\n",
    "sns.lineplot(data=nIDT, x=\"EntryDate\", y=\"Count\", hue=\"InfractionText\", ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Infractions per Day per Type per Street"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_streets = df_streets.Street.tolist()\n",
    "\n",
    "# number of Infractions per Day per Type per Street\n",
    "nIDTS = df.copy()\n",
    "nIDTS = nIDTS[(nIDTS[\"Street\"].isin(popular_streets)) & (nIDTS[\"InfractionText\"].isin(popular_infractions))]\n",
    "nIDTS = nIDTS.groupby(['EntryDate', 'InfractionText', 'Street']) \\\n",
    "                                .count() \\\n",
    "                                .rename(columns={'Block':'Count'})[['Count']]\\\n",
    "                                .reset_index()\n",
    "\n",
    "nIDTS['Street_str'] = nIDTS['Street'].astype(str)\n",
    "nIDTS['InfractionText_str'] = nIDTS['InfractionText'].astype(str)\n",
    "nIDTS['Street_&_Infraction'] = nIDTS['Street_str'] + [\"___\"]*len(nIDTS) + nIDTS['InfractionText_str']\n",
    "nIDTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = pyplot.subplots(figsize=(25,20))\n",
    "sns.lineplot(data=nIDTS, x=\"EntryDate\", y=\"Count\", hue=\"Street_&_Infraction\", ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nIDTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J4jPpcKOutZ5"
   },
   "outputs": [],
   "source": [
    "nIDTS_filter = nIDTS[nIDTS['Street']==87]\n",
    "fig, ax = pyplot.subplots(figsize=(25,20))\n",
    "sns.lineplot(data=nIDTS_filter, x=\"EntryDate\", y=\"Count\", hue=\"Street_&_Infraction\", ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nIDTS_filter[['Count']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# External data\n",
    "## Holiday dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday_df = pd.read_csv('holidays.csv', sep=',',parse_dates=['date'])\n",
    "holiday_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nInfractionsPerDay = df.groupby(['EntryDate']) \\\n",
    "    .count() \\\n",
    "    .rename(columns={'Block': 'Count'})[['Count']] \\\n",
    "    .reset_index()\n",
    "nInfractionsPerDay[\"dayOfWeek\"] = nInfractionsPerDay.apply(\n",
    "    lambda row: row.EntryDate.weekday(), axis=1)\n",
    "nInfractionsPerDay = pd.merge(nInfractionsPerDay, holiday_df, how='left', left_on='EntryDate',\n",
    "                              right_on='date').drop(columns=['date']).fillna(0, downcast='infer')\n",
    "nInfractionsPerDay[\"holiday\"] = nInfractionsPerDay.apply(\n",
    "    lambda row: 0 if row.holiday == 0 else 1, axis=1)\n",
    "\n",
    "h = nInfractionsPerDay[[\"Count\"]].hist()\n",
    "\n",
    "nInfractionsPerDay[[\"Count\"]].describe([.1, .2, .3, .4, .5, .6, .7, .8, .9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_dic = {\n",
    "    1: [0, 970.6],\n",
    "    2: [970.6, 1160.2],\n",
    "    3: [1160.2, 1309.8],\n",
    "    4: [1309.8, 1448.4],\n",
    "    5: [1448.4, -1]\n",
    "}\n",
    "\n",
    "\n",
    "def map_to_cat(num):\n",
    "    for key, ranges in mapping_dic.items():\n",
    "        if num >= ranges[0] and (ranges[1] == -1 or num < ranges[1]):\n",
    "            return key\n",
    "\n",
    "    print(\"Negative values not allowed\")\n",
    "    return -1\n",
    "\n",
    "\n",
    "dfCat = nInfractionsPerDay.copy()\n",
    "dfCat[\"countCat\"] = dfCat.apply(lambda row: map_to_cat(row.Count), axis=1)\n",
    "\n",
    "del dfCat[\"Count\"]\n",
    "dfCat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parking_holidays = pd.merge(df,holiday_df, how='left', left_on='EntryDate', right_on='date').drop(columns= ['date'])\n",
    "#df_parking_holidays[df_parking_holidays['EntryDate'] == '2017-02-20'] #look at infraction in one holliday\n",
    "df_parking_holidays.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_holiday_infraction_count = df_parking_holidays.holiday.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday_df.holiday.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Family day, Thanksgiving, Remembrance day and Victoria day are the holidays with the most infractions.  \n",
    "Note the absence of 2 holidays: christmas day and new year's day. Because stores, attractions and many services are closed in these holidays, there is less traffic and perhaps less fiscalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infractions per holiday per year\n",
    "infrac_per_holyday_year = df_parking_holidays.groupby(['Year', 'holiday']) \\\n",
    "                                .count() \\\n",
    "                                .rename(columns={'Block':'Count'})[['Count']]\\\n",
    "                                .reset_index()\n",
    "\n",
    "fig, ax = pyplot.subplots(figsize=(15,12))\n",
    "sns.barplot(x=\"holiday\", y=\"Count\", hue=\"Year\", data=infrac_per_holyday_year, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ADICIONAR TEXTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infractions per holiday per year per type\n",
    "infrac_per_holyday_year_type = df_parking_holidays.groupby(['Year', 'holiday', 'Infraction_Type']) \\\n",
    "                                .count() \\\n",
    "                                .rename(columns={'Block':'Count'})[['Count']]\\\n",
    "                                .reset_index()\n",
    "infrac_per_holyday_year_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_infr=['METERED', 'STOP OR PARK'] # The most popular infrations\n",
    "# 'OTHER', 'LARGE VEHICLE PARKED INCORRECTLY', 'CAUSE, ALLOW OR PERMIT', \n",
    "# 'WATER LAWN/FIELD... OUTSIDE PERMITTED HOUR/DAY',\n",
    "#'WASTING WATER','WATER - OTHER']\n",
    "\n",
    "fig, ax = pyplot.subplots(nrows=3, ncols=1, figsize=(15,12))\n",
    "sns.barplot(x=\"holiday\", y=\"Count\", hue=\"Infraction_Type\", hue_order=order_infr,\n",
    "            data=infrac_per_holyday_year_type[infrac_per_holyday_year_type.Year==2017], ax=ax[0])\n",
    "sns.barplot(x=\"holiday\", y=\"Count\", hue=\"Infraction_Type\", hue_order=order_infr,\n",
    "            data=infrac_per_holyday_year_type[infrac_per_holyday_year_type.Year==2018], ax=ax[1])\n",
    "sns.barplot(x=\"holiday\", y=\"Count\", hue=\"Infraction_Type\", hue_order=order_infr,\n",
    "            data=infrac_per_holyday_year_type[infrac_per_holyday_year_type.Year==2019], ax=ax[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ADICIONAR TEXTO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new dataset for timeseries analysis on oracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parking_holidays_count_street_and_day = df_parking_holidays\\\n",
    "    .groupby(['InfractionText', 'EntryDate', 'holiday'], dropna=False, as_index=False)['Street'].count().\\\n",
    "    rename(columns={'Street':'infraction_count'})\n",
    "pd.set_option('max_colwidth', 400)\n",
    "df_parking_holidays_count_street_and_day.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parking_holidays_count_street_and_day.holiday.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_parking_holidays_count_street_and_day.to_csv(r'/home/bsilva/Desktop/irregular_parking_count_infractions_by_day.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parking_holidays_count_by_street_and_day = df_parking_holidays\\\n",
    "    .groupby(['Street','EntryDate', 'holiday'], dropna=False, as_index=False)['InfractionText'].count().\\\n",
    "    rename(columns={'InfractionText':'infraction_count'})\n",
    "pd.set_option('max_colwidth', 400)\n",
    "df_parking_holidays_count_by_street_and_day.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_parking_holidays_count_by_street_and_day.to_csv(r'/home/bsilva/Desktop/irregular_parking_count_street_by_day.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parking_holidays_only = df_parking_holidays[df_parking_holidays['holiday'].notnull()]\n",
    "df_parking_holidays_only = df_parking_holidays_only.groupby('holiday')\n",
    "df_parking_holidays_only.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Oracle Cloud Infratructure to perform forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARIMA, SARIMA, ETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LQ90XveiBN6A"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gSDath2nr1fq"
   },
   "source": [
    "## Conclusions\n",
    "\n",
    "### Scalability and Impact\n",
    "Tell us how applicable and scalable your solution is if you were to implement it in a city. Identify possible limitations and measure the potential social impact of your solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CGmbES9GszEv"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0XBiBOyAl2Sv"
   },
   "source": [
    "### Future Work\n",
    "Now picture the following scenario: imagine you could have access to any type of data that could help you solve this challenge even better. What would that data be and how would it improve your solution? üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5gK3heTKl7qz"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Notebook Submission Template.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
